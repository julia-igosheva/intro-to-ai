{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA2: Gestures Recongnition Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "In this assignment, you are asked to design and implement algorithms that recognize at least three hand shapes in a video stream (such as making a fist, thumbs up, thumbs down, pointing with an index finger etc.) or gestures (such as waving with one or both hands, swinging, drawing something in the air etc.). You must design a graphical display that responds to the recognition of the hand shapes or gestures and write a report that includes quantitative results (e.g., a confusion matrix, ROC analysis, etc.). \n",
    "*For this assignment, we will use \"recognition\" and \"detection\" interchangebly for gestures. We also use the term \"gesture\" to represent \"hand shape.\"\n",
    "\n",
    "*To simplify your task, you may want to select gestures that are sufficiently \"different.\" For example, \"scissor,\" \"paper,\" and \"rock\" are three clealy different hand shapes used in a well-known game. Your gestures, however, should not only include pointing with different numbers of fingers.\n",
    "\n",
    "*Your gesture should include at least one static hand shape and one dynamic gesture.\n",
    "\n",
    "For your system, you may want to use some of the following computer vision techniques that we discussed in the computer vision lectures and labs:\n",
    "\n",
    "1. how to access video camera input with OpenCV\n",
    "2. background differencing: D(x,y,t) = |I(x,y,t)-I(x,y,0)|\n",
    "    - https://docs.opencv.org/3.0-beta/modules/imgproc/doc/motion_analysis_and_object_tracking.html\n",
    "3. frame-to-frame differencing: D’(x,y,t) = |I(x,y,t)-I(x,y,t-1)|\n",
    "4. template matching (e.g., create templates of a closed hand and an open hand)\n",
    "5. motion energy templates (union of binary difference images over a window of time)\n",
    "6. skin-color detection (e.g., thresholding red and green pixel values)\n",
    "7. horizontal and vertical projections to find bounding boxes of ”movement blobs” or ”skin-color blobs”\n",
    "8. size, position, and orientation of ”movement blobs” or ”skin-color blobs”\n",
    "9. circularity of ”movement blobs” or ”skin-color blobs”\n",
    "10. tracking the position and orientation of moving objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    #if not successful, exit program\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open the video cam\")\n",
    "        return -1\n",
    "\n",
    "    success, prev_frame = cap.read()\n",
    "    \n",
    "    #if not successful, exit program\n",
    "    if not success:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "        return -1\n",
    "  \n",
    "    #create a window \n",
    "    cv2.namedWindow(\"MyVideo0\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.imshow(\"MyVideo0\",prev_frame)\n",
    "    # read a new frame from video\n",
    "       \n",
    "    #create other windows\n",
    "    cv2.namedWindow(\"FrameDifferencing\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.namedWindow(\"MotionHistory\", cv2.WINDOW_AUTOSIZE)\n",
    "    cv2.namedWindow(\"SkinDetection\", cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "    prev_frame = cv2.resize(prev_frame,(130,130))\n",
    "    fMH1 = np.zeros((prev_frame.shape[0], prev_frame.shape[1], 1), dtype = \"uint8\")\n",
    "    fMH2 = fMH1.copy()\n",
    "    fMH3 = fMH1.copy()\n",
    "    myMotionHistory = deque([fMH1, fMH2, fMH3])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    okayTp = cv2.imread(\"okay.png\",0)\n",
    "    okayTpCopy = okayTp.copy()\n",
    "    cv2.threshold(okayTp, 20, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    coolTp = cv2.imread(\"thumb.png\",0)\n",
    "    coolTpCopy = coolTp.copy()\n",
    "    cv2.threshold(coolTp, 20, 255, cv2.THRESH_BINARY)\n",
    " \n",
    "    hiTp = cv2.imread(\"hi.png\",0)\n",
    "    hiTpCopy = hiTp.copy()\n",
    "    cv2.threshold(hiTp, 20, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    \n",
    "    while(True):\n",
    "        success, curr_frame = cap.read()\n",
    "        curr_frame = cv2.resize(curr_frame,(130,130))\n",
    "        curr_frame=cv2.flip(curr_frame,1)\n",
    "        \n",
    "        if not success:\n",
    "            print(\"Cannot read a frame from video stream\")\n",
    "            break\n",
    "            \n",
    "        cv2.imshow(\"MyVideo0\", prev_frame)    \n",
    "            \n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        \n",
    "           \n",
    "        #cv2.imshow('frame',curr_frame)\n",
    "\n",
    "        # b) Skin color detection\n",
    "        mySkin = mySkinDetect(curr_frame)\n",
    "        cv2.imshow('SkinDetection',mySkin)\n",
    "        \n",
    "        \n",
    "        rpos = -1\n",
    "        maxVal = 0.3\n",
    "        matchLoc = 0\n",
    "        label = \"sign not detected\"\n",
    "\n",
    "        meth = 'cv2.TM_CCOEFF_NORMED'\n",
    "        \n",
    "        okayTp = okayTpCopy.copy()\n",
    "        coolTp = coolTpCopy.copy()\n",
    "        hiTp = hiTpCopy.copy()\n",
    "\n",
    "        meth = eval(meth)\n",
    "        color = (0,0,0)\n",
    "        \n",
    "        resOkay = cv2.matchTemplate(mySkin, okayTp, meth)\n",
    "        min_valOkay, max_valOkay, min_locOkay, max_locOkay = cv2.minMaxLoc(resOkay)\n",
    "         \n",
    "        resCool = cv2.matchTemplate(mySkin, coolTp, meth)\n",
    "        min_valCool, max_valCool, min_locCool, max_locCool = cv2.minMaxLoc(resCool)\n",
    "        \n",
    "        resHi = cv2.matchTemplate(mySkin, hiTp, meth)\n",
    "        min_valHi, max_valHi, min_locHi, max_locHi = cv2.minMaxLoc(resHi)\n",
    "        \n",
    "        \n",
    "        if(max_valOkay > maxVal):\n",
    "            matchLoc = max_locOkay\n",
    "            maxVal = max_valOkay\n",
    "            label = \"okay\"\n",
    "            color = (255,0,0)\n",
    "            \n",
    "        \n",
    "        if(max_valCool > maxVal):\n",
    "            matchLoc = max_locCool\n",
    "            maxVal = max_valCool\n",
    "            label = \"cool\"\n",
    "            color = (0,0,255)\n",
    "            \n",
    "        if(max_valHi > maxVal):\n",
    "            matchLoc = max_locHi\n",
    "            maxVal = max_valHi\n",
    "            label = \"hi\"\n",
    "            color = (0,255,0)\n",
    "        \n",
    "        \n",
    "        # motion gesture detection \n",
    "        \n",
    "        \n",
    "    \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(curr_frame, label, (50,60), font, 2, color, 3, cv2.LINE_AA)\n",
    "        maxVal = 0\n",
    "\n",
    "        cv2.imshow(\"MyVideo0\",prev_frame)\n",
    "        \n",
    "        # c) Background differencing\n",
    "        \n",
    "        dest = myFrameDifferencing(prev_frame, curr_frame)\n",
    "        cv2.imshow(\"FrameDifferencing\", dest)\n",
    "        \n",
    "        # d) Motion History\n",
    "        \n",
    "        latest = myMotionHistory.popleft()\n",
    "        \n",
    "        \n",
    "#         diff = myFrameDifferencing(dest, latest)\n",
    "#         if (diff < myMotionHistory):\n",
    "#             label = \"waving\"\n",
    "#             color = (255,255,0)\n",
    "        \n",
    "        myMotionHistory.append(dest)\n",
    "        myMH = myMotionEnergy(myMotionHistory)\n",
    "        cv2.imshow('MotionHistory',myMH)\n",
    "\n",
    "        prev_frame = curr_frame\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    return 0\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. find and segment the hand region \n",
    "    - separate frontground from background (running averages)\n",
    "    - \n",
    "2. count the number of fingers in the region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myFrameDifferencing(prev, curr):\n",
    "    \n",
    "    dst = cv2.absdiff(curr, prev)\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    _, dst = cv2.threshold(dst, 50, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMotionEnergy(mh):\n",
    "    # the window of time is 3\n",
    "    mh0 = mh[0] #d0\n",
    "    mh1 = mh[1] #d1\n",
    "    mh2 = mh[2] #d2\n",
    "    dst = np.zeros((mh0.shape[0], mh0.shape[1], 1), dtype = \"uint8\")\n",
    "\n",
    "    for i in range(dst.shape[0]):\n",
    "        for j in range(dst.shape[1]):\n",
    "            if mh0[i,j] == 255 or mh1[i,j] == 255 or mh2[i,j] == 255:\n",
    "                dst[i,j] = 255\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mySkinDetect(src):\n",
    "    dst = np.zeros((src.shape[0], src.shape[1], 1), dtype = \"uint8\")\n",
    "    for i in range(src.shape[0]):\n",
    "        for j in range(src.shape[1]):\n",
    "            #b,g,r = src[i,j]\n",
    "            b = int(src[i,j][0])\n",
    "            g = int(src[i,j][1])\n",
    "            r = int(src[i,j][2])\n",
    "            if(r>95 and g>40 and b>20 and max(r,g,b)-min(r,g,b)>15 and abs(r-g)>15 and r>g and r>b):\n",
    "                dst[i,j] = 255\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
